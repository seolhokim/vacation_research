{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence to sequence\n",
    "#https://medium.com/@jongdae.lim/%EA%B8%B0%EA%B3%84-%ED%95%99%EC%8A%B5-machine-learning-%EC%9D%80-%EC%A6%90%EA%B2%81%EB%8B%A4-part-5-83b7a44b797a\n",
    "\n",
    "#paper\n",
    "#https://arxiv.org/pdf/1506.05869.pdf\n",
    "\n",
    "#image to sequence\n",
    "#https://cs.stanford.edu/people/karpathy/\n",
    "\n",
    "#목소리 변환\n",
    "#https://www.youtube.com/watch?v=klnfWhPGPRs&t=1019s\n",
    "#https://www.slideshare.net/carpedm20/deview-2017-80824162\n",
    "\n",
    "#Encoder-Decoder Models for Text Summarization in Keras\n",
    "#https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/\n",
    "\n",
    "#lstm shape\n",
    "#https://www.google.co.kr/search?q=lstm+shape&oq=lstm+shape&aqs=chrome..69i57j0l5.2073j0j7&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "#lstm study\n",
    "#https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/\n",
    "\n",
    "\n",
    "#attention mechanism.?\n",
    "#Byte Pair Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = \"C:\\\\Users\\\\sh2\\\\Downloads\\\\OpinRankDatasetWithJudgments\\\\hotels\\\\data\"\n",
    "collect_data = \"C:\\\\Users\\\\sh2\\\\Downloads\\\\OpinRankDatasetWithJudgments\\\\hotels\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dir = glob.glob(total_data+\"\\\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data_dir = glob.glob(all_data_dir[0]+\"\\\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(collect_data+\"all_data.txt\",'ab') as txt:\n",
    "    for i in range(len(all_data_dir)):\n",
    "        file_dir = glob.glob(all_data_dir[i]+\"/*\")\n",
    "        \n",
    "        for j in range(len(file_dir)):\n",
    "            with open(file_dir[j],'rb') as f:\n",
    "                print(j)\n",
    "                data = f.read()\n",
    "                txt.write(data)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(collect_data+\"all_data.txt\",'r',encoding = 'utf-8') as f:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = Word2Vec(test,size=1,window=1,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'LSTM' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-02a4e4a7ced4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlstm1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_h\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mstate_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'LSTM' object is not iterable"
     ]
    }
   ],
   "source": [
    "lstm1, state_h ,state_c = LSTM(1, return_state = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (3,1))\n",
    "lstm1, state_h, state_c = LSTM(2, return_sequences=True,return_state=True)(inputs)\n",
    "model = Model(inputs = inputs, outputs = [lstm1,state_h,state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_13/transpose_1:0' shape=(?, ?, 2) dtype=float32>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_13/while/Exit_2:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_13/while/Exit_3:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1,2,3]).reshape(1,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.05857584, -0.00939669],\n",
       "         [ 0.15495731, -0.02222049],\n",
       "         [ 0.24603046, -0.02993613]]], dtype=float32),\n",
       " array([[ 0.24603046, -0.02993613]], dtype=float32),\n",
       " array([[ 0.26787663, -0.07139179]], dtype=float32)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
