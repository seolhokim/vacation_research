{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://opencv-python.readthedocs.io/en/latest/doc/24.imageTemplateMatch/imageTemplateMatch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageGrab\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#키를 눌러주는 tool\n",
    "import win32com.client\n",
    "shell = win32com.client.Dispatch(\"WScript.Shell\")\n",
    "shell.SendKeys('asdasd')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#마우스 클릭\n",
    "import pyautogui\n",
    "sleep(3)\n",
    "pyautogui.click(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#게임화면을 받아옴\n",
    "def grab_screen(_driver = None):\n",
    "    #bbox = region of interest on the entire screen\n",
    "    screen =  np.array((ImageGrab.grab(bbox=(18,120,550,1250))) )\n",
    "    #image = process_img(screen)#processing image as required\n",
    "    image = process_img(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def process_img(image):\n",
    "\n",
    "    image = image[300:800,:] #img[y:y+h, x:x+w]\n",
    "    image = cv2.resize(image, (0,0), fx = 0.5, fy = 0.5) \n",
    "    image = cv2.Canny(image, threshold1 = 100, threshold2 = 200) #apply the canny edge detection\n",
    "    return  image \n",
    "\n",
    "grab_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.run()\n",
    "    def run(self):\n",
    "        shell.SendKeys('l')\n",
    "        sleep(0.1)\n",
    "    def turn(self):\n",
    "        shell.SendKeys('a')\n",
    "        sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "img_rows , img_cols = 40,20\n",
    "img_channels = 4 #We stack 4 frames\n",
    "ACTIONS = 2\n",
    "def buildmodel():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (8, 8), strides=(4, 4), padding='same',input_shape=(img_cols,img_rows,img_channels)))  #20*40*4\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse',optimizer=adam)\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start button\n",
    "\n",
    "from PIL import ImageGrab\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def grab_screen(_driver = None):\n",
    "    \n",
    "    screen =  np.array((ImageGrab.grab(bbox=(10,30,350,650))) )\n",
    "    image = process_img(screen)#processing image as required\n",
    "    #cv2.imshow(\"yes\",image)\n",
    "    #key = cv2.waitKey(5000)\n",
    "    \n",
    "    #if key == ord('s'): #s키가 입력된거면 이미지 저장\n",
    "    #    cv2.destroyWindow(screen)\n",
    "        \n",
    "    return image\n",
    "\n",
    "def process_img(image):\n",
    "    #game is already in grey scale canvas, canny to get only edges and reduce unwanted objects(clouds)\n",
    "    # resale image dimensions\n",
    "    #image = cv2.resize(image, (0,0), fx = 0.5, fy = 0.5) \n",
    "    #crop out the dino agent from the frame\n",
    "    \n",
    "    #image = image[100:600,:] #img[y:y+h, x:x+w]\n",
    "    image = cv2.resize(image, (0,0), fx = 0.5, fy = 0.5) \n",
    "    image = cv2.Canny(image, threshold1 = 120, threshold2 = 250) #apply the canny edge detection\n",
    "    return  image \n",
    "\n",
    "\n",
    "def grab_train():\n",
    "    screen =  np.array((ImageGrab.grab(bbox=(10,300,300,500)))) \n",
    "    image = process_img(screen)#processing image as required\n",
    "    #cv2.imshow(\"yes\",image)\n",
    "    #key = cv2.waitKey(3000)\n",
    "    return image\n",
    "import matplotlib.pyplot as plt\n",
    "large_image = grab_screen()\n",
    "small_image = cv2.imread(\"./image_video/start_button.PNG\",0)\n",
    "small_image = process_img(small_image)\n",
    "w,h = small_image.shape[::-1]\n",
    "\n",
    "methods = ['cv2.TM_CCOEFF']\n",
    "methods = eval(methods[0])\n",
    "result = cv2.matchTemplate(small_image, large_image,methods)\n",
    "\n",
    "min_val,max_val,min_loc,max_loc = cv2.minMaxLoc(result)\n",
    "top_left = max_loc\n",
    "bottom_right =(top_left[0]+w,top_left[1]+h)\n",
    "cv2.rectangle(large_image,top_left,bottom_right,255,5)\n",
    "\n",
    "plt.imshow(large_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start button click\n",
    "from PIL import ImageGrab\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyautogui\n",
    "\n",
    "def real_grab_screen(_driver = None):\n",
    "    \n",
    "    screen =  np.array((ImageGrab.grab(bbox=(10,30,350,650))) )\n",
    "    image = real_process_img(screen)#processing image as required\n",
    "    return image\n",
    "\n",
    "def real_process_img(image):\n",
    "    image = cv2.Canny(image, threshold1 = 100, threshold2 = 200)\n",
    "    return  image \n",
    "\n",
    "def start_button_click():\n",
    "    large_image = real_grab_screen()\n",
    "    small_image = cv2.imread(\"./image_video/start_button.PNG\",0)\n",
    "    small_image = real_process_img(small_image)\n",
    "    w,h = small_image.shape[::-1]\n",
    "\n",
    "    methods = ['cv2.TM_CCOEFF']\n",
    "    methods = eval(methods[0])\n",
    "    result = cv2.matchTemplate(small_image, large_image,methods)\n",
    "\n",
    "    min_val,max_val,min_loc,max_loc = cv2.minMaxLoc(result)\n",
    "    top_left = max_loc\n",
    "    bottom_right =(top_left[0]+w,top_left[1]+h)\n",
    "\n",
    "    pyautogui.click(top_left[0]+w/2,top_left[1]+h/2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스타트버튼 클릭과 버튼있는지없는지 함수\n",
    "def start_button_click():\n",
    "    large_image = real_grab_screen()\n",
    "    small_image = cv2.imread(\"./image_video/start_button.PNG\",0)\n",
    "    small_image = real_process_img(small_image)\n",
    "    if exists(large_image, small_image,0.7):\n",
    "        w,h = small_image.shape[::-1]\n",
    "        min_val,max_val,min_loc,max_loc = cv2.minMaxLoc(result)\n",
    "        top_left = max_loc\n",
    "        pyautogui.click(top_left[0]+w/2,top_left[1]+h/2)\n",
    "def exists(image, template, thresh):\n",
    "    \"\"\"\n",
    "    Returns True if template is in Image with probability of at least thresh\n",
    "    :param image: \n",
    "    :param template: \n",
    "    :param thresh: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    digit_res = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "    loc = np.where(digit_res >= thresh)\n",
    "\n",
    "    if len(loc[-1]) == 0:\n",
    "        return False\n",
    "\n",
    "    for pt in zip(*loc[::-1]):\n",
    "        if digit_res[pt[1]][pt[0]] == 1:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_button_exists():\n",
    "    large_image = real_grab_screen()\n",
    "    small_image = cv2.imread(\"./image_video/up_button.PNG\",0)\n",
    "    small_image = real_process_img(small_image)\n",
    "    \n",
    "    return (exists(large_image,small_image,0.7))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
