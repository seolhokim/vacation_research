{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#infinite_stairs를 정리해서 제대로 만듬\n",
    "#게임은 좌측화면 맨위 640 * 320 인가로 띄웠음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageGrab\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import sleep\n",
    "import win32com.client\n",
    "import pyautogui\n",
    "from time import time\n",
    "from keras.layers import Dense, Conv2D , Activation , Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import random\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def grab_screen(self, _driver = None): #전체화면 받아옴\n",
    "        screen =  np.array((ImageGrab.grab(bbox=(10,30,350,650))) )\n",
    "        image = self.process_img(screen)\n",
    "        return image\n",
    "\n",
    "    def process_img(self,image): #resize를 절반으로해줌\n",
    "        image = cv2.resize(image, (0,0), fx = 0.11, fy = 0.2) \n",
    "        image = cv2.Canny(image, threshold1 = 120, threshold2 = 250)\n",
    "        #print(image.shape)\n",
    "        return  image \n",
    "\n",
    "    def grab_train(self): #학습할곳만 받아옴 (40x 32로함)\n",
    "        screen =  np.array((ImageGrab.grab(bbox=(10,300,300,500)))) \n",
    "        image = self.process_img(screen)\n",
    "        return image\n",
    "\n",
    "    def real_grab_screen(self,_driver = None):\n",
    "\n",
    "        screen =  np.array((ImageGrab.grab(bbox=(10,30,350,650))) )\n",
    "        image = self.real_process_img(screen)#processing image as required\n",
    "        return image\n",
    "\n",
    "    def real_process_img(self,image):\n",
    "        image = cv2.Canny(image, threshold1 = 100, threshold2 = 200)\n",
    "        return  image \n",
    "    \n",
    "    def start_button_click(self): #start_button이 있다면 클릭해줌\n",
    "        large_image = self.real_grab_screen()\n",
    "        small_image = cv2.imread(\"./image_video/start_button.PNG\",0)\n",
    "        small_image = self.real_process_img(small_image)\n",
    "        if self.exists(large_image, small_image,0.7):\n",
    "            w,h = small_image.shape[::-1]\n",
    "            result = cv2.matchTemplate(large_image, small_image, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val,max_val,min_loc,max_loc = cv2.minMaxLoc(result)\n",
    "            top_left = max_loc\n",
    "            pyautogui.click(top_left[0]+w/2,top_left[1]+h/2)\n",
    "            pyautogui.moveTo(100,100)\n",
    "    def exists(self, image, template, thresh):\n",
    "        digit_res = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "        loc = np.where(digit_res >= thresh)\n",
    "\n",
    "        if len(loc[-1]) == 0:\n",
    "            return False\n",
    "\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            if digit_res[pt[1]][pt[0]] == 1:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def up_button_exists(self): #up_button 이 있다면 게임이 안끝난것.\n",
    "        large_image = self.real_grab_screen()\n",
    "        small_image = cv2.imread(\"./image_video/up_button.PNG\",0)\n",
    "        small_image = self.real_process_img(small_image)\n",
    "\n",
    "        return not (self.exists(large_image,small_image,0.7))\n",
    "    \n",
    "    def OKButton_exists(self):\n",
    "        large_image = self.real_grab_screen()\n",
    "        small_image = cv2.imread(\"./image_video/OK.PNG\",0)\n",
    "        small_image = self.real_process_img(small_image)\n",
    "        \n",
    "        return self.exists(large_image,small_image,0.7)\n",
    "    \n",
    "    def OK_clear(self):\n",
    "        if self.OKButton_exists():\n",
    "            large_image = self.real_grab_screen()\n",
    "            small_image = cv2.imread(\"./image_video/OK.PNG\",0)\n",
    "            small_image = self.real_process_img(small_image)\n",
    "            w,h = small_image.shape[::-1]\n",
    "            result = cv2.matchTemplate(large_image, small_image, cv2.TM_CCOEFF_NORMED)\n",
    "            min_val,max_val,min_loc,max_loc = cv2.minMaxLoc(result)\n",
    "            top_left = max_loc\n",
    "            pyautogui.click(top_left[0]+w/2,top_left[1]+h)\n",
    "            sleep(1)\n",
    "            pyautogui.click(370,570)\n",
    "            sleep(1)\n",
    "            pyautogui.moveTo(800,800)\n",
    "        else :\n",
    "            pass\n",
    "    \n",
    "    def bonus_clear(self):\n",
    "        if self.bonus_exists():\n",
    "            pyautogui.click(300,330)\n",
    "            sleep(1)\n",
    "            pyautogui.click(170,480)\n",
    "            sleep(1)\n",
    "            pyautogui.click(370,570)\n",
    "            sleep(1)\n",
    "            pyautogui.moveTo(800,800)\n",
    "        \n",
    "    def bonus_exists(self):\n",
    "        large_image = self.real_grab_screen()\n",
    "        small_image = cv2.imread(\"./image_video/bonus.PNG\",0)\n",
    "        small_image = self.real_process_img(small_image)\n",
    "        \n",
    "        return self.exists(large_image,small_image,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyautogui.moveTo(170,550)\n",
    "#sleep(5)\n",
    "#pyautogui.moveTo(370,570)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        #self.run()\n",
    "        self.shell = win32com.client.Dispatch(\"WScript.Shell\")\n",
    "        self.epsilon = 1. #e\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.action_size = 2\n",
    "        self.learning_rate = 0.0001\n",
    "        self.gamma = 0.95\n",
    "        self.target_model = self.build_model()\n",
    "        self.main_model = self.build_model()\n",
    "        self.memory = deque(maxlen =2000)\n",
    "        \n",
    "        self.image_channels = 4 #4개의 채널\n",
    "        self.img_rows = 0 #이 세개 왜 build_model에서 찾지못함?\n",
    "        self.img_cols = 0\n",
    "        self.set_frame()\n",
    "        \n",
    "    def set_frame(self):\n",
    "        self.img_rows = 40\n",
    "        self.img_cols = 32\n",
    "        \n",
    "    def run(self):\n",
    "        self.shell.SendKeys('l')\n",
    "        sleep(0.005)\n",
    "        return 0\n",
    "    \n",
    "    def turn(self):\n",
    "        self.shell.SendKeys('a')\n",
    "        sleep(0.005)\n",
    "        return 1\n",
    "    \n",
    "    def act_thinking(self,state):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay  \n",
    "            \n",
    "        if np.random.rand() <= self.epsilon:     \n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        act_values = self.main_model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "    \n",
    "    def act(self,state):\n",
    "        res = self.act_thinking(state)\n",
    "        if res == 1:\n",
    "            self.turn()\n",
    "            return 1\n",
    "        else :\n",
    "            self.run()\n",
    "            return 0\n",
    "    def _huber_loss(self, target, prediction):\n",
    "        # sqrt(1+error^2)-1\n",
    "        error = prediction - target\n",
    "        return K.mean(K.sqrt(1+K.square(error))-1, axis=-1)\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.img_rows = 40\n",
    "        self.img_cols = 32\n",
    "        self.img_channels = 4\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (8, 8), strides=(4, 4), padding='same',input_shape=\\\n",
    "                         (self.img_cols, self.img_rows, self.img_channels)))  #32*40*4\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dense(self.action_size))\n",
    "        adam = Adam(lr=self.learning_rate)\n",
    "        model.compile(loss=self._huber_loss,optimizer=adam)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, rewar, next_state, done):\n",
    "        self.memory.append((state,action,reward,next_state,done))\n",
    "    \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        #target_model\n",
    "        #main_model\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            Q = self.main_model.predict(state)\n",
    "            #print(Q,\"Q\")\n",
    "            #print(Q[0][action],'Q[0][action]')\n",
    "            \n",
    "            if done:\n",
    "                Q[0][action] = reward\n",
    "                \n",
    "            else :\n",
    "                t = self.target_model.predict(next_state)[0]\n",
    "                #print(t,\"t\")\n",
    "                #print(reward,'reward')\n",
    "                Q[0][action] = reward + self.gamma * np.amax(t)\n",
    "            \n",
    "            self.main_model.fit(state,Q,epochs=1,verbose=0)\n",
    "            \n",
    "    def save_model(self,name):\n",
    "        agent.main_model.save_weights(name)\n",
    "    \n",
    "    def load_model(self,name):\n",
    "        agent.main_model.load_weights(name)\n",
    "        agent.target_model.load_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_model(\"infinite_stairs_ver_02_epochs_500.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(start_time):\n",
    "    score = time()-start_time\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load_model('infinite_stairs_ver_01_epochs_300.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 100\n",
    "batch_size= 32\n",
    "\n",
    "\n",
    "game = GameState()\n",
    "agent = Agent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes= 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/300, score: 19, e: 0.009921\n",
      "episode: 1/300, score: 20, e: 0.009921\n",
      "episode: 2/300, score: 4, e: 0.009921\n",
      "episode: 3/300, score: 28, e: 0.009921\n",
      "episode: 4/300, score: 12, e: 0.009921\n",
      "episode: 5/300, score: 44, e: 0.009921\n",
      "episode: 6/300, score: 32, e: 0.009921\n",
      "episode: 7/300, score: 26, e: 0.009921\n",
      "episode: 8/300, score: 26, e: 0.009921\n",
      "episode: 9/300, score: 42, e: 0.009921\n",
      "episode: 10/300, score: 25, e: 0.009921\n",
      "episode: 11/300, score: 45, e: 0.009921\n",
      "episode: 12/300, score: 32, e: 0.009921\n",
      "episode: 13/300, score: 53, e: 0.009921\n",
      "episode: 14/300, score: 44, e: 0.009921\n",
      "episode: 15/300, score: 50, e: 0.009921\n",
      "episode: 16/300, score: 26, e: 0.009921\n",
      "episode: 17/300, score: 25, e: 0.009921\n",
      "episode: 18/300, score: 33, e: 0.009921\n",
      "episode: 19/300, score: 48, e: 0.009921\n",
      "episode: 20/300, score: 34, e: 0.009921\n",
      "episode: 21/300, score: 35, e: 0.009921\n",
      "episode: 22/300, score: 13, e: 0.009921\n",
      "episode: 23/300, score: 13, e: 0.009921\n",
      "episode: 24/300, score: 52, e: 0.009921\n",
      "episode: 25/300, score: 14, e: 0.009921\n",
      "episode: 26/300, score: 6, e: 0.009921\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-7416c0219bd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-135-7416c0219bd5>\u001b[0m in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-116-57ce852e5726>\u001b[0m in \u001b[0;36mreplay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1712\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2475\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2476\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def start():\n",
    "    for e in range(episodes):\n",
    "\n",
    "        game.start_button_click()\n",
    "        agent.run()\n",
    "        start_time = time()\n",
    "        state = game.grab_train()\n",
    "        state = np.stack((state,state,state,state),\\\n",
    "                         axis=2).reshape(1, agent.img_cols, agent.img_rows,agent.img_channels)\n",
    "\n",
    "        done=False\n",
    "\n",
    "        for time_t in range(1000):\n",
    "\n",
    "            action = agent.act(state)\n",
    "            done = game.up_button_exists()\n",
    "\n",
    "            reward = get_score(start_time)\n",
    "            if done:\n",
    "                reward = -10\n",
    "            if (time_t >= 50):\n",
    "                reward = 100\n",
    "            #print(reward)\n",
    "            next_state = game.grab_train()\n",
    "            next_state = np.stack((next_state,next_state,next_state,next_state),\\\n",
    "                         axis=2).reshape(1, agent.img_cols, agent.img_rows,agent.img_channels)\n",
    "            agent.remember(state, action, reward, next_state,done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                sleep(2)\n",
    "                game.OK_clear()\n",
    "                game.bonus_clear()\n",
    "                agent.target_model.set_weights(agent.main_model.get_weights())\n",
    "                score_board.append(time_t)    \n",
    "                print(\"episode: {}/{}, score: {}, e: {:.4}\"\n",
    "                        .format(e, episodes, time_t, agent.epsilon))\n",
    "                if len(score_board) > 3 :\n",
    "                    if score_board[-1] == 0 and score_board[-2] == 0 and score_board[-3] == 0 and score_board[-4] == 0:\n",
    "                        pyautogui.click(170,550)\n",
    "                        sleep(5)\n",
    "                        pyautogui.click(370,570)\n",
    "                break\n",
    "\n",
    "            if len(agent.memory) > batch_size:\n",
    "                agent.replay(batch_size)\n",
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class MC:\n",
    "    def __init__(self):\n",
    "        self.game = GameState()\n",
    "        self.agent = Agent()\n",
    "    def start(self):\n",
    "        self.game.start_button_click()\n",
    "        self.agent.run()\n",
    "        start_time = time()\n",
    "  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 1000\n",
    "batch_size= 32\n",
    "done=False\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    game = GameState()\n",
    "    agent = Agent()\n",
    "    game.start_button_click()\n",
    "    agent.run()\n",
    "    start_time = time()\n",
    "    '''\n",
    "        action = predict하고\n",
    "        \n",
    "        end_time = time() 구함\n",
    "        if done : \n",
    "    '''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x1e0b7a37cc0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.main_model.save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.main_model.save_weights(\"infinite_stairs_ver_01_epochs_300.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
