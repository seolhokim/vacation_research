{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "import xgboost as xgb\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>anger_score</th>\n",
       "      <th>disgust_score</th>\n",
       "      <th>fear_score</th>\n",
       "      <th>joy_score</th>\n",
       "      <th>sadness_score</th>\n",
       "      <th>anger_count</th>\n",
       "      <th>disgust_count</th>\n",
       "      <th>fear_count</th>\n",
       "      <th>joy_count</th>\n",
       "      <th>sadness_count</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>23.678598</td>\n",
       "      <td>1.862068</td>\n",
       "      <td>3.365532</td>\n",
       "      <td>129.260966</td>\n",
       "      <td>22.046661</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>26</td>\n",
       "      <td>12381.11</td>\n",
       "      <td>12380.43</td>\n",
       "      <td>12476.93</td>\n",
       "      <td>12319.35</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>23.436641</td>\n",
       "      <td>1.568504</td>\n",
       "      <td>1.807040</td>\n",
       "      <td>110.107599</td>\n",
       "      <td>28.552481</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>33</td>\n",
       "      <td>12263.58</td>\n",
       "      <td>12381.04</td>\n",
       "      <td>12381.04</td>\n",
       "      <td>12185.09</td>\n",
       "      <td>-0.9500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>17.595715</td>\n",
       "      <td>3.441165</td>\n",
       "      <td>3.351268</td>\n",
       "      <td>103.535217</td>\n",
       "      <td>17.206766</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>21</td>\n",
       "      <td>12270.99</td>\n",
       "      <td>12263.73</td>\n",
       "      <td>12372.94</td>\n",
       "      <td>12203.63</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16.065135</td>\n",
       "      <td>4.921378</td>\n",
       "      <td>5.183304</td>\n",
       "      <td>102.417106</td>\n",
       "      <td>15.457086</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "      <td>18</td>\n",
       "      <td>12285.15</td>\n",
       "      <td>12270.24</td>\n",
       "      <td>12332.71</td>\n",
       "      <td>12137.98</td>\n",
       "      <td>0.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>16.869910</td>\n",
       "      <td>1.555661</td>\n",
       "      <td>3.334624</td>\n",
       "      <td>121.630811</td>\n",
       "      <td>14.709462</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>18</td>\n",
       "      <td>12341.83</td>\n",
       "      <td>12285.45</td>\n",
       "      <td>12402.61</td>\n",
       "      <td>12238.34</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  anger_score  disgust_score  fear_score   joy_score  \\\n",
       "0  2011      4   11    23.678598       1.862068    3.365532  129.260966   \n",
       "1  2011      4   12    23.436641       1.568504    1.807040  110.107599   \n",
       "2  2011      4   13    17.595715       3.441165    3.351268  103.535217   \n",
       "3  2011      4   14    16.065135       4.921378    5.183304  102.417106   \n",
       "4  2011      4   15    16.869910       1.555661    3.334624  121.630811   \n",
       "\n",
       "   sadness_score  anger_count  disgust_count  fear_count  joy_count  \\\n",
       "0      22.046661           28              2           4        150   \n",
       "1      28.552481           28              2           2        128   \n",
       "2      17.206766           21              4           4        121   \n",
       "3      15.457086           19              6           6        121   \n",
       "4      14.709462           20              2           4        141   \n",
       "\n",
       "   sadness_count     close      open      high       low  change  \n",
       "0             26  12381.11  12380.43  12476.93  12319.35  0.0001  \n",
       "1             33  12263.58  12381.04  12381.04  12185.09 -0.9500  \n",
       "2             21  12270.99  12263.73  12372.94  12203.63  0.0006  \n",
       "3             18  12285.15  12270.24  12332.71  12137.98  0.0012  \n",
       "4             18  12341.83  12285.45  12402.61  12238.34  0.0046  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일단 score랑 count만가지고 train해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12381.11\n",
       "1    12263.58\n",
       "2    12270.99\n",
       "3    12285.15\n",
       "4    12341.83\n",
       "Name: close, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data.iloc[:,3:13]\n",
    "train_label = data.iloc[:,13]\n",
    "train_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data,data['open']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger_score</th>\n",
       "      <th>disgust_score</th>\n",
       "      <th>fear_score</th>\n",
       "      <th>joy_score</th>\n",
       "      <th>sadness_score</th>\n",
       "      <th>anger_count</th>\n",
       "      <th>disgust_count</th>\n",
       "      <th>fear_count</th>\n",
       "      <th>joy_count</th>\n",
       "      <th>sadness_count</th>\n",
       "      <th>open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.678598</td>\n",
       "      <td>1.862068</td>\n",
       "      <td>3.365532</td>\n",
       "      <td>129.260966</td>\n",
       "      <td>22.046661</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>26</td>\n",
       "      <td>12380.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.436641</td>\n",
       "      <td>1.568504</td>\n",
       "      <td>1.807040</td>\n",
       "      <td>110.107599</td>\n",
       "      <td>28.552481</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>33</td>\n",
       "      <td>12381.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.595715</td>\n",
       "      <td>3.441165</td>\n",
       "      <td>3.351268</td>\n",
       "      <td>103.535217</td>\n",
       "      <td>17.206766</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>21</td>\n",
       "      <td>12263.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.065135</td>\n",
       "      <td>4.921378</td>\n",
       "      <td>5.183304</td>\n",
       "      <td>102.417106</td>\n",
       "      <td>15.457086</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "      <td>18</td>\n",
       "      <td>12270.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.869910</td>\n",
       "      <td>1.555661</td>\n",
       "      <td>3.334624</td>\n",
       "      <td>121.630811</td>\n",
       "      <td>14.709462</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>18</td>\n",
       "      <td>12285.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger_score  disgust_score  fear_score   joy_score  sadness_score  \\\n",
       "0    23.678598       1.862068    3.365532  129.260966      22.046661   \n",
       "1    23.436641       1.568504    1.807040  110.107599      28.552481   \n",
       "2    17.595715       3.441165    3.351268  103.535217      17.206766   \n",
       "3    16.065135       4.921378    5.183304  102.417106      15.457086   \n",
       "4    16.869910       1.555661    3.334624  121.630811      14.709462   \n",
       "\n",
       "   anger_count  disgust_count  fear_count  joy_count  sadness_count      open  \n",
       "0           28              2           4        150             26  12380.43  \n",
       "1           28              2           2        128             33  12381.04  \n",
       "2           21              4           4        121             21  12263.73  \n",
       "3           19              6           6        121             18  12270.24  \n",
       "4           20              2           4        141             18  12285.45  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 11)\n",
      "(369,)\n"
     ]
    }
   ],
   "source": [
    "#3일 뒤를 예측\n",
    "train_data = train_data.iloc[:-3,:]\n",
    "train_label = train_label.iloc[3:]\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369,)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scale_data = scaler.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_train_label = np.log1p(train_label)\n",
    "logged_train_label = np.array(logged_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle_cv(model, n_folds=5):\n",
    "    kf = KFold(n_folds, shuffle=True).get_n_splits(scale_data)\n",
    "    rmse= np.sqrt(-cross_val_score(model, scale_data,logged_train_label, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.09,\n",
    "                             learning_rate=0.009, \n",
    "                              n_estimators=100,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213,\n",
    "                             random_state =7, nthread = -1)\n",
    "xgb_m = xgb.XGBRegressor(leraning_rate = 0.05, n_estimators= 1000)\n",
    "GBoost = GradientBoostingRegressor(max_depth=2, learning_rate=0.005,min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "\n",
    "KRR = KernelRidge(alpha=0.1, kernel='polynomial', degree=1, coef0=5)\n",
    "\n",
    "ENet = ElasticNet(alpha=0.005, l1_ratio=.6, random_state=3)\n",
    "\n",
    "lasso = Lasso(alpha =0.005, random_state=1)\n",
    "\n",
    "RForest = RandomForestRegressor(n_estimators=100,max_depth=2,min_samples_leaf=2\\\n",
    "                               ,min_weight_fraction_leaf=0.5,max_leaf_nodes=2\\\n",
    "                                ,random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6341967179036887\n",
      "0.0422841419325357\n",
      "0.021313119649035477\n",
      "0.023543197815842378\n",
      "0.025565595199804864\n"
     ]
    }
   ],
   "source": [
    "print(rmsle_cv(model_xgb))\n",
    "print(rmsle_cv(GBoost))\n",
    "print(rmsle_cv(KRR))\n",
    "print(rmsle_cv(ENet))\n",
    "print(rmsle_cv(lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055375069546392666"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (ENet, KRR,GBoost,RForest,lasso ,model_xgb))\n",
    "\n",
    "rmsle_cv(averaged_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5개 모두시 떨어짐\n",
    "#model_xgb, ENet, KRR, lasso . 0.056998897272156866\n",
    "#model_xgb, ENet, KRR          0.0569513660909768 \n",
    "#model_xgb, ENet , lasso       0.056966904668101906\n",
    "#model_xgb, ENet,              0.05693818530913114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_data\n",
    "#logged_train_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            \n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                \n",
    "                self.base_models_[i].append(instance)\n",
    "                \n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "      \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        \n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.054000115716498764"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet,KRR,lasso,RForest),meta_model =  GBoost)\n",
    "rmsle_cv(stacked_averaged_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base_models = (ENet,lasso,KRR,model_xgb),meta_model =  GBoost 0.053922348347839634\n",
    "#base_models = (ENet,lasso,KRR,model_xgb),meta_model =  GBoost 0.054324193590506976\n",
    "#base_models = (ENet,KRR),meta_model =  GBoost 0.0537208976739747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_data\n",
    "#logged_train_label\n",
    "pd.DataFrame(scale_data).to_csv(\"Last_train.csv\",index=False)\n",
    "pd.DataFrame(logged_train_label).to_csv(\"Last_label.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = scale_data[:-100]\n",
    "test = scale_data[-100:]\n",
    "train_label = train_label[:-100]\n",
    "test_label = train_label[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingAveragedModels(base_models=(ElasticNet(alpha=0.002, copy_X=True, fit_intercept=True, l1_ratio=0.6,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=3, selection='cyclic', tol=0.0001, warm_start=False), KernelRidge(alpha=0.1, coef0=5, degree=1, gamma=None, kernel='polynomia..._estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=6, verbose=0, warm_start=False)),\n",
       "            meta_model=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.005, loss='huber', max_depth=2,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=15, min_samples_split=10,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "             presort='auto', random_state=5, subsample=1.0, verbose=0,\n",
       "             warm_start=False),\n",
       "            n_folds=5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet,KRR,lasso,RForest),meta_model =  GBoost)\n",
    "stacked_averaged_models.fit(train,logged_train_label[:-100]) #train_label은 log를 넣었었다가 안되서 그냥값을 넣어본거임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059743052171724174"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_m = xgb.XGBRegressor(leraning_rate = 0.01, n_estimators= 100)\n",
    "rmsle_cv(xgb_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_predict(model,X_data,Y_data,cut_num=5):\n",
    "    '''\n",
    "    split data into 5 groups\n",
    "    \n",
    "    1.fit group 1\n",
    "    \n",
    "    2.predict group i and fit group i ( i = 2,3,4,5)\n",
    "    \n",
    "    3.and result is (model, predict_result)\n",
    "    '''\n",
    "    \n",
    "    ind_lst = [int((len(X_data)/cut_num) * i) for i in range(6)]\n",
    "    model.fit(X_data[ind_lst[0]:ind_lst[4]],Y_data[ind_lst[0]:ind_lst[4]])\n",
    "    result = [Y_data[:ind_lst[4]]]\n",
    "\n",
    "    for i in range(ind_lst[4],ind_lst[5]):\n",
    "        temp = model.predict(X_data[i].reshape(1,-1))\n",
    "        result.append(temp)\n",
    "        #model.fit(X_data[i].reshape(1,-1),Y_data[i].reshape(1,-1))\n",
    "    \n",
    "    result = np.array(list(itertools.chain(*result)))\n",
    "    return result\n",
    "result = train_and_predict(lasso,scale_data,logged_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.expm1(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = stacked_averaged_models.predict(test)\n",
    "#res = np.expm1(res)\n",
    "real_value = np.expm1(logged_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = [x for x in range(1,len(real_value)+1)]\n",
    "x2_range = [x for x in range(1, len(result)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369,)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x200a9338fd0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "plt.figure(1)\n",
    "plt.plot(x_range,real_value)\n",
    "plt.plot(x2_range,result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
