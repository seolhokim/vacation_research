{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid token (<ipython-input-1-0aa53cfe70b3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-0aa53cfe70b3>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    20180722_alpha_0_025_decrease167\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid token\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "#https://datascienceschool.net/view-notebook/6927b0906f884a67b0da9310d3a581ee/\n",
    "\n",
    "좋은모델 \n",
    "\n",
    "20180722_alpha_0_025_decrease167\n",
    "#하던페이지\n",
    "'''\n",
    "https://github.com/eagle705/Korean_NER_CNN_BiLSTM/blob/master/CNN_BiLSTM.py\n",
    "https://github.com/MSWon/Sentimental-Analysis\n",
    "https://towardsdatascience.com/sentiment-analysis-using-rnns-lstm-60871fa6aeba\n",
    "https://programmers.co.kr/learn/courses/21/lessons/1697\n",
    "http://konlpy-ko.readthedocs.io/ko/v0.4.3/morph/\n",
    "https://datascienceschool.net/view-notebook/6927b0906f884a67b0da9310d3a581ee/\n",
    "https://radimrehurek.com/gensim/models/word2vec.html\n",
    "https://github.com/dhkdn9192/KoreanNLP/blob/master/main/w2v_with_news/word2vec_make_model-digitaltimes.py\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-45\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Twitter \n",
    "import glob\n",
    "import re\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data load\n",
    "\n",
    "data_name = glob.glob(\"데이터위치\")\n",
    "tagger = Twitter()\n",
    "\n",
    "def data_read(data_place):\n",
    "\n",
    "    f = open(data_place,'r')\n",
    "    txt = f.read()\n",
    "\n",
    "    hangle = re.compile('[^ ㄱ-ㅣ가-힣0-9]+')\n",
    "    result = hangle.sub('',txt)\n",
    "    #print(\"result clear\")\n",
    "    result = tagger.pos(result,norm=True,stem = True)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def train_data_make(data):\n",
    "    r = []\n",
    "    results = []\n",
    "    jung_bok = \"\"\n",
    "    for (word, pumsa) in data:\n",
    "        if not pumsa in [\"Josa\", \"Eomi\", \"Punctuation\"] and jung_bok !=word:\n",
    "            r.append(word)\n",
    "            jung_bok = word\n",
    "    results.append((\" \".join(r)).strip())  \n",
    "    return results\n",
    "def train_data_to_txt(results,name = ''):\n",
    "    with open(name,'w') as fp:\n",
    "        fp.write(results)\n",
    "        \n",
    "def train_data_creation(data_dir,data_name):\n",
    "    for i in range(len(data_name)):\n",
    "        result = data_read(data_name[i])\n",
    "        result = train_data_make(result)\n",
    "        dir_name = data_dir+str(i)+'.txt'\n",
    "        train_data_to_txt(result[0],dir_name)\n",
    "        print(i,\"/\",len(data_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train\n",
    "\n",
    "for i in range(1,len(data)):\n",
    "    train_data = word2vec.LineSentence(data[i])\n",
    "    model.train(train_data,total_examples = model.corpus_count, epochs = model.epochs)\n",
    "    name = './model/w2v_model_20180722_'+str(i)+'.model'\n",
    "    model.save(name)\n",
    "    model.init_sims(replace=True)\n",
    "'''\n",
    "\n",
    "def train_model(model_dir,model,data,model_name):\n",
    "    for i in range(len(data)):\n",
    "        if model.alpha >=0.0003:\n",
    "            model.alpha -= 0.0002\n",
    "            model.min_alpha = model.alpha\n",
    "        train_data = word2vec.LineSentence(data[i])\n",
    "        model.train(train_data, epochs = model.epochs,total_examples = model.corpus_count) #,total_examples = model.corpus_count\n",
    "        name = model_dir+model_name+str(i)+'.model' #날짜조정해주기\n",
    "        model.save(name)\n",
    "        model.init_sims(replace=True)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob.glob(\"./*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\last_train.txt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#새로생성시\n",
    "#train_data = word2vec.LineSentence(data[0])\n",
    "#model = Word2Vec(train_data,size = 200, window = 10, min_count = 2,sg= 1,alpha=0.025, min_alpha =0.025 ) #로 생성함.skip\n",
    "#train_model('./model',model,data)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"./model/20180728_news_train_model20.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = word2vec.LineSentence(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/last_train_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model('./model/',model,data[0],'last_train_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\last_train.txt'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob.glob('news_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x16705884940>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_2('./model/',model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-45\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ie-45\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('워싱턴', 0.6922904253005981),\n",
       " ('미합중국', 0.6895014047622681),\n",
       " ('캘리포니아', 0.6859111189842224),\n",
       " ('일리노이', 0.6815937757492065),\n",
       " ('메릴랜드', 0.6618004441261292),\n",
       " ('뉴욕', 0.6615024209022522),\n",
       " ('루이지애나', 0.6530179977416992),\n",
       " ('캔자스', 0.6363495588302612),\n",
       " ('매사추세츠', 0.6326195597648621),\n",
       " ('코네티컷', 0.6321420669555664)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.most_similar(\"미국\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/20180723_news.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_2(\"./model\",model,movie_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = glob.glob(\"./movie_subtitle/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./movie_subtitle\\\\1.txt',\n",
       " './movie_subtitle\\\\10.txt',\n",
       " './movie_subtitle\\\\11.txt',\n",
       " './movie_subtitle\\\\12.txt',\n",
       " './movie_subtitle\\\\13.txt',\n",
       " './movie_subtitle\\\\14.txt',\n",
       " './movie_subtitle\\\\15.txt',\n",
       " './movie_subtitle\\\\16.txt',\n",
       " './movie_subtitle\\\\17.txt',\n",
       " './movie_subtitle\\\\18.txt',\n",
       " './movie_subtitle\\\\2.txt',\n",
       " './movie_subtitle\\\\3.txt',\n",
       " './movie_subtitle\\\\4.txt',\n",
       " './movie_subtitle\\\\7.txt',\n",
       " './movie_subtitle\\\\8.txt',\n",
       " './movie_subtitle\\\\9.txt',\n",
       " './movie_subtitle\\\\Inside.Job.2010.720p.Bluray.txt',\n",
       " './movie_subtitle\\\\Margin+Call.2011.txt',\n",
       " './movie_subtitle\\\\Rogue.Trader.1999.K4FH.ShareReactor.kor.txt',\n",
       " './movie_subtitle\\\\The+Wolf+Of+Wall+Street+2013+720p+BRRip+x264+AC3-JYK.txt',\n",
       " './movie_subtitle\\\\Wall.Street.1987.REMASTERED.1080p.BluRay.x264.DTS-FGT.txt',\n",
       " './movie_subtitle\\\\Wall.Street.Money.Never.Sleeps.2010.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_creation('./movie_subtitle/movie/',movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob.glob(\"./movie_subtitle/movie/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13558, 17820)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = word2vec.LineSentence(data[0])\n",
    "model.train(train_data,total_examples = model.corpus_count, epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x169d482fb00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model('./model',model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ie-45\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ie-45\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('천재', 0.6905375719070435),\n",
       " ('안나', 0.687379002571106),\n",
       " ('인구', 0.6628733277320862),\n",
       " ('더구나', 0.662299633026123),\n",
       " ('계약', 0.6542538404464722),\n",
       " ('각각', 0.6461697816848755),\n",
       " ('진출', 0.639185905456543),\n",
       " ('베이징', 0.6306732892990112),\n",
       " ('살아나다', 0.6247203350067139),\n",
       " ('교육', 0.6222289204597473)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('미국')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
