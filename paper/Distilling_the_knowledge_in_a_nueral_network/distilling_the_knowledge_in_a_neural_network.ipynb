{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distilling the Knowledge in a Neural Newtwork\n",
    "#논문 읽기 1편\n",
    "# Softmax 구현\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_max(lst):\n",
    "    T = 1\n",
    "    exp_sum = 0\n",
    "    for value in lst:\n",
    "        exp_sum += np.exp(value/T)\n",
    "    lst = list(map(lambda x : np.exp(x/T)/exp_sum,lst))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6590011388859679, 0.2424329707047139, 0.09856589040931818]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= [2,1,0.1]\n",
    "soft_max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T의 값이 커질수록 좀더 soft한 softmax를 구할수 있음\n",
    "\n",
    "def softer_soft_max(lst):\n",
    "    T = 10\n",
    "    exp_sum = 0\n",
    "    for value in lst:\n",
    "        exp_sum += np.exp(value/T)\n",
    "    lst = list(map(lambda x : np.exp(x/T)/exp_sum,lst))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36605947074479267, 0.3312243063563281, 0.3027162228988793]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= [2,1,0.1]\n",
    "softer_soft_max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T의 작아지면 harder\n",
    "\n",
    "def harder_soft_max(lst):\n",
    "    T = 0.1\n",
    "    exp_sum = 0\n",
    "    for value in lst:\n",
    "        exp_sum += np.exp(value/T)\n",
    "    lst = list(map(lambda x : np.exp(x/T)/exp_sum,lst))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999545965290099, 4.539786844809093e-05, 5.602542051131752e-09]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= [2,1,0.1]\n",
    "harder_soft_max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hard모델과 soft모델을 혼용해 사용함으로써 더 좋은 모델을 만들 수 있다.\n",
    "#첫번째는 soft모델로, soft_max한 값.\n",
    "#T를 사용하는이유 \n",
    "#hard한 target과 soft한 target에서의 contribution 때문.\n",
    "#T^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "가장 심플한 변형 모형안에서, 지식은 변형모형 으로 전달된다. \n",
    "변형된set 위에서 학습 됨 또는 soft T 를 씀으로써. 각각의 변형된 set(1,0으로 학습된)\n",
    "위에서. \n",
    "하지만 hard T는 사용된다. T =  1로 학습한 뒤에도.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "애초에 T=1로 학습을하니까 이후에 ensemble학습은 T를 조금더 soft하게 해야한다는뜻\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "correct labels이 알려졌을때, 이 방법은 좋은 효과가있다.\n",
    "correct label을 soft T로 만들고, 이 두 다른 T끼리를 비교.\n",
    "\n",
    " # 구현해보자\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "첫번째 function은 soft T , high T로 인해 계산됨.\n",
    "두번째 function은 T = 1로 계산됨\n",
    "최고의 결과는 2번째 function에 낮은 가중치로 최상의 결과를 얻음\n",
    "\n",
    " # 구현해보자\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "soft 타겟에 의해 생성 된 gredient의 크기가\n",
    "1/T^2로 스케일되기 때문에 hard 타겟과 soft 타겟을 \n",
    "모두 사용할 때 T^2로 곱하는 것이 중요\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "어떻게 1/T^2 가되는지 볼까\n",
    "\n",
    "크로스엔트로피를 distilled한 모델 Zi로 미분시 1/T(Qi-Pi) #why?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "분석해논 git \n",
    "\n",
    "https://jamiekang.github.io/2017/05/21/distilling-the-knowledge-in-a-neural-network/\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "logit 값이란 hidden layer 내의 weight \n",
    "logit 내에 noise를 넣어 더 좋은 성능 구현가능\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "hinton ensemble을 값싸게 구현하기 위해\n",
    "soft한 model을 이용해 값싸게 작은 모형을 구현 가능하다.\n",
    "\n",
    "이외에도 비슷한(확률분포, oversampling(?)을 통해 비슷한 구현 가능)\n",
    "\n",
    "Temperature은 실험을 통해 구해야함.(주로 2.5~5)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "hinton 은 cost function 을 \n",
    "cross - entropy 에서 개별 확률을\n",
    "softmax로구한 확률값으로 대체\n",
    "\n",
    "+ original set 의 cross - entropy 와 함께 가중치를 두어 구현(알파값도 실험치)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "이 논문의 가장 큰 목적\n",
    "\n",
    "큰 ensemble 모델의 weight(정보) 를 single-shallow net으로 이전가능\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"mnist_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test.iloc[:,0]\n",
    "test_data = test.iloc[:,1:]\n",
    "test_data =test_data.values.reshape(test_data.shape[0],28,28,1)\n",
    "test_label = pd.get_dummies(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = train.iloc[:,0]\n",
    "train = train.iloc[:,1:]\n",
    "train_data =train.values.reshape(train.shape[0],28,28,1)\n",
    "train_label = pd.get_dummies(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train.iloc[476,:].values\n",
    "for i in range(1,len(a)):\n",
    "    print('{0:3.0f}'.format(a[i]),end ='')\n",
    "    if i % 28 == 0 :\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>1x10</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  1x10  ...    28x19  28x20  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0    0.0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.apply(lambda x:x/255)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0 63120190194194195154 20  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 67245253182178178188253 89  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0 85254180 49  0  0  0  0157164  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0166189 97  0  0  0  0  0134225  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  5  5  5  0  0  0  0  0139238  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  6217203  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 75253 98  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  8 79139245255174 79 16  0166220  9  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0 16206253194119128225253232187254119  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0131249137  4  0  0  8 64196253254245186 90 20  0  0  0  0  5  0  0  0\n",
      "  0  0  0  0  0254136  0  0  0  0 24145253204 60121207253236195176120154211  0  0  0\n",
      "  0  0  0  0  0254180 75 89149202239249130 12  0  0  2 30 96135218253218 91  0  0  0\n",
      "  0  0  0  0  0206254254248224224162 31  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  6 45 93 54  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sh2\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import pooling, Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_model_making():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28, 1)))\n",
    "    model.add(Conv2D(32, 3, 3, activation='relu'))\n",
    "    model.add(pooling.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(32, 3, 3, activation='relu'))\n",
    "    model.add(Conv2D(32, 3, 3, activation='relu'))\n",
    "    model.add(pooling.MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sh2\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\sh2\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \n",
      "C:\\Users\\sh2\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.5764 - acc: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18179c6cb70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = big_model_making()\n",
    "model.fit(train_data,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.81781889e-12, 3.82948451e-10, 2.13601581e-10, ...,\n",
       "        1.00000000e+00, 7.99351037e-12, 6.68811562e-10],\n",
       "       [7.27402920e-08, 2.56217436e-06, 9.99996662e-01, ...,\n",
       "        6.37295017e-08, 3.41233488e-07, 4.49243247e-11],\n",
       "       [1.08955200e-08, 9.99991536e-01, 8.53272155e-08, ...,\n",
       "        5.89617777e-08, 5.09476365e-07, 3.14438031e-09],\n",
       "       ...,\n",
       "       [8.55458274e-11, 1.39591361e-08, 7.95396027e-10, ...,\n",
       "        2.12555236e-08, 9.86166469e-06, 9.28411191e-06],\n",
       "       [7.56218839e-08, 4.39068906e-08, 1.66050569e-07, ...,\n",
       "        1.61085086e-06, 1.87745672e-02, 2.03792752e-05],\n",
       "       [1.61423692e-08, 1.00647005e-10, 9.79074377e-10, ...,\n",
       "        3.27256169e-12, 2.51560928e-09, 6.02208505e-10]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'googLe_net_catching_up' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f139968c9fc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoogLe_net_catching_up\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'googLe_net_catching_up' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def googLe_net_catching_up(train_data):\n",
    "    inp =Input(shape = (train_data.shape[1] , train_data.shape[2],train_data.shape[3]))\n",
    "    conv1= Conv2D(64,(3,3),padding='same',activation='relu')(input)\n",
    "    conv1_normal = BatchNormalization()(conv1)\n",
    "    conv1_pooling = MaxPooling2D(pool_size =(2,2),padding='valid')(conv1_normal)\n",
    "    conv1_dropout = Dropout(0.3)(conv1_pooling)\n",
    "     #,strides=(1,1) 를뺌\n",
    "    \n",
    "    conv2 =Conv2D(64,(3,3),padding='same',activation='relu')(conv1_dropout)\n",
    "    conv2_normal = BatchNormalization()(conv2)\n",
    "    conv2_pooling = MaxPooling2D(pool_size =(2,2),padding='valid')(conv2_normal)\n",
    "    conv2_dropout = Dropout(0.3)(conv2_pooling)\n",
    "    \n",
    "    \n",
    "    conv3 =Conv2D(64,(3,3),padding='same',activation='relu')(conv2_dropout)\n",
    "    conv3_normal = BatchNormalization()(conv3)\n",
    "    conv3_pooling = MaxPooling2D(pool_size =(2,2),padding='valid')(conv3_normal)\n",
    "    conv3_dropout = Dropout(0.3)(conv3_pooling)\n",
    "    model = Model(inputs =inp, outputs=conv3_dropout)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
